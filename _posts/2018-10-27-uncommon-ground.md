---
layout: post
title: Uncommon Ground
---
Augmented reality breaks a key assumption we make every day: we presume the other sees what we see.
How does this change our face-to-face communication?

I have the opportunity to run research studies as a volunteer at the San Jose Tech Museum.
It has its perks, including watching people have first-time, natural interations with new technology.
A few days ago, a few of my co-workers at the Museum encountered a fundamental change AR makes to face-to-face conversation.

I've recently started piloting my next study in a redesigned booth in the AR/VR corner of the museum.
A co-worker in the booth nearby was curious what was happening in my booth, and because the museum was not busy that afternoon, I brough over the HoloLens AR headset for her to try out.
I gave her the directions to put on the headset (which is a challenge in itself!), stepped through the menus, and was able to see and place some virtual models.

A few minutes later, the person working the next shift dropped by the booth.
He also tried on the HoloLens and placed a few holograms in the space.
However, the other co-worker, the one who had tried it on first, fixated on the weird air-gestures the second was making.
The one wearing the headset didn't notice.
To use a surprisingly apropos phrase, he was "in his own world."
If asked, I'm sure she certainly would been able to explain why he was making weird gestures.
She hadn't forgotten how the headset worked.
Nevertheless the interactions in the headset were weird enough to elicit from us watching a little bit of awkward laugher.
The behavior we saw was strange on a deeper level than mere knowledge of the headset could explain away.

I'd like to examine this interaction through the [theory of common ground](http://www.psychology.sunysb.edu/sbrennan-/papers/old_clarkbrennan.pdf) put forward by Herb Clark.
In short, communication is built upon "common ground" - that which both of us are aware of the fact that both of us understand.
As with many good theories, it seems simple yet is insightful.
In any conversation, we are not only contributing and listening, but also looking for evidence that the other understood what was said.
Especially in difficult technical conversations, I have given and received many a blank look.
That nonverbal cue signals some re-explanation or topic change.
We notice and adjust naturally because we are also maintaining our own awareness of the other's understanding.

What makes common ground theory relevant to AR is that much of our common ground is assumed.
We do not verbally establish the philosophical meaning of the existence of a cup before we begin talking about it - it is there in front of us, and that is sufficient for our purposes.
Only after we discuss something misunderstandable do we expect positive evidence of understanding.

We take for granted that what we see in space is really and truly there - as that is the case 99.9% of the time - and so it can influence our verbal and nonverbal behaviors.
On a very straightforward level, it was odd to see hand motions without any referents - I could not see what AR object my co-worker was pointing to or moving around.
But also on a second level, it didn't immediately make sense to my co-worker how he looked.
To him, the virtual objects were certainly present, and so his gaze direction and hand gestures [though they were unfamiliar] were at least directed towards objects he was experiencing.
The *uncommon ground* we had - one of us seeing these holograms, and two of us who did not - affected our communication behavior.

This isn't the only case in which I've noticed the effect of uncommon ground.
In the lab, we often run tours, including demonstrations of recent experiments.
One step our process includes is instructing participants to walk towards an AR sphere [about as big as a soccer ball] in order to get them acquainted with the headset.
The person wearing the headset began walking towards the ball, which happened to be two feet from some of the other tour members.
One fellow tour attendee looked at him uncomfortably, and as a precaution, stepped out of his way.
She couldn't see where the ball was, and so she didn't perceive why he was walking towards her.
But again, the person in the headset did not notice or interpret the nonverbal behavior of his fellow tour attendee, because for him, the ball was certainly present, and there would be no reason to expect her to not understand that.

I've noticed this in a third case, again at the Tech Museum.
There were times I put the headset on to fix a technical issue while the museumgoer / participant was sitting in the experiment room with me.
I was air-tapping and blooming my way through the HoloLens menus to fix the bug, but I'd try to make conversation.
I had trouble with those initiations.
Perhaps they hadn't expected me to begin a conversation with them?
It took me some time to realize it was because I was looking off in a different direction - normally if I were to start a conversation, I would look in their direction, showing them some attention.
Once again, uncommon ground leads to breaks in the flow of communication.

It is not difficult to believe that a lack of shared knowledge leads to miscommunications.
These stories are vignettes for how AR may have caused some problems.
However, is it going to stay this way? What implications does this have for AR design?

Today's AR goggles are primarily individual experiences
Up to this point, it takes a non-trivial amount of programming to share AR content.
But recently, there have been steps made towards sharing AR experiences.
ARKit and ARCore, the AR libraries for iOS and Android respectively, both include "cloud anchors" that let multiple people share an AR space.
Even the Hololens now has a way to let mobile devices see content rendered in HoloLens.
Clearly, these are technical solutions that enable sharing, and there is no technical restriction on sharing content between two people.
However, I don't think we as people will reach a point where we will share all our virtual content with everyone around us, and receive the content everyone else wants to show us.
Therefore, given the use of AR devices, there will be uncommon ground.

The second question is whether we will adjust socially and personally to the strangeness AR brings to us.
Perhaps AR will be like a Bluetooth headset - strange at first, but ultimately accepted socially.
Even then, many find Bluetooth headsets annoying.
Without a visual cue, e.g, another person nearby or a hand held up to the ear, the strangeness of the situation grabs our attention.
Only after we make the conscious connection that Bluetooth headsets exist and this person may be using one do we return to whatever originally had our attention, though with some unconscious unease.
Do we want AR headsets to become invisible, too? Then this visual cue would be lost.
Perhaps we would be more uncertain and uneasy in these cases of uncommon ground.

The popular use of AR will lead to many situations like the ones I've detailed above.
Will this be something we will change for the future?
The answer to that question relies on others:
What are the effects of these situations? 
Are we more distracted, more irritable, etc, when others are violating the conversational norms we expect?
How quickly might we become used to these situations? What are the drawbacks to becoming used to these violations?
How should we design AR devices or content in order to reduce these violations?
These questions pose interesting directions for future work.

AR devices have a lot of potential - including the potential to break common ground, leading to miscommunications.
Part of AR research is understanding and mitigating its downsides.
I'm eager to see how we will approach this problem in the future!


